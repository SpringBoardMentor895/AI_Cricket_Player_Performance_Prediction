{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IPL Cricket Player Performance Prediction - Feature Engineering\n",
        "\n",
        "This notebook performs comprehensive feature engineering for IPL cricket player performance prediction.\n",
        "\n",
        "## Pipeline Overview:\n",
        "1. Load and prepare data\n",
        "2. Aggregate to player-match level\n",
        "3. Engineer advanced features (PUT, rolling, venue, PvP, career)\n",
        "4. Create target labels\n",
        "5. Feature selection and preprocessing\n",
        "6. Time-series aware train-test split\n",
        "7. Create feature pipeline\n",
        "8. Save artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Loading and Preparing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "1. LOADING AND PREPARING DATA\n",
            "============================================================\n",
            "Data loaded successfully!\n",
            "Shape: (145967, 41)\n",
            "Date range: 2008-04-18 00:00:00 to 2017-05-19 00:00:00\n",
            "Unique batters: 406\n",
            "Unique venues: 35\n",
            "Unique bowling teams: 13\n"
          ]
        }
      ],
      "source": [
        "def load_and_prepare_data():\n",
        "    \"\"\"Load merged data and prepare for feature engineering\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"1. LOADING AND PREPARING DATA\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Load merged data\n",
        "    df = pd.read_csv(\"merged_data.csv\")\n",
        "    \n",
        "    # Convert date column to datetime\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    \n",
        "    # Rename batsman to batter for consistency\n",
        "    df[\"batter\"] = df[\"batsman\"]\n",
        "    \n",
        "    print(f\"Data loaded successfully!\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"Date range: {df[\"date\"].min()} to {df[\"date\"].max()}\")\n",
        "    print(f\"Unique batters: {df[\"batter\"].nunique()}\")\n",
        "    print(f\"Unique venues: {df[\"venue\"].nunique()}\")\n",
        "    print(f\"Unique bowling teams: {df[\"bowling_team\"].nunique()}\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Load the data\n",
        "df = load_and_prepare_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Aggregating to Player-Match Level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "2. AGGREGATING TO PLAYER-MATCH LEVEL\n",
            "============================================================\n",
            "Player-match level data shape: (9054, 12)\n",
            "Sample data:\n",
            "           batter  match_id       date  \\\n",
            "0  A Ashish Reddy       346 2012-04-29   \n",
            "1  A Ashish Reddy       352 2012-05-04   \n",
            "2  A Ashish Reddy       359 2012-05-08   \n",
            "3  A Ashish Reddy       373 2012-05-18   \n",
            "4  A Ashish Reddy       376 2012-05-20   \n",
            "\n",
            "                                       venue                 bowling_team  \\\n",
            "0                           Wankhede Stadium               Mumbai Indians   \n",
            "1            MA Chidambaram Stadium, Chepauk          Chennai Super Kings   \n",
            "2  Rajiv Gandhi International Stadium, Uppal                 Punjab Kings   \n",
            "3  Rajiv Gandhi International Stadium, Uppal             Rajasthan Royals   \n",
            "4  Rajiv Gandhi International Stadium, Uppal  Royal Challengers Bangalore   \n",
            "\n",
            "   batsman_runs  ball  is_wicket  is_boundary  is_six  is_four  strike_rate  \n",
            "0            10    10          1            1       0        1        100.0  \n",
            "1             3     3          1            0       0        0        100.0  \n",
            "2             8     8          1            0       0        0        100.0  \n",
            "3            10     4          0            0       0        0        250.0  \n",
            "4             4     5          1            0       0        0         80.0  \n"
          ]
        }
      ],
      "source": [
        "def aggregate_to_player_match(df):\n",
        "    \"\"\"Aggregate ball-by-ball data to player-match level\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"2. AGGREGATING TO PLAYER-MATCH LEVEL\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Aggregate to player-match level\n",
        "    player_match = df.groupby([\"batter\", \"match_id\", \"date\", \"venue\", \"bowling_team\"]).agg({\n",
        "        \"batsman_runs\": \"sum\",\n",
        "        \"ball\": \"count\",\n",
        "        \"is_wicket\": \"sum\",\n",
        "        \"is_boundary\": \"sum\",\n",
        "        \"is_six\": \"sum\",\n",
        "        \"is_four\": \"sum\"\n",
        "    }).reset_index()\n",
        "    \n",
        "    # Calculate strike rate\n",
        "    player_match[\"strike_rate\"] = (player_match[\"batsman_runs\"] / player_match[\"ball\"] * 100).round(2)\n",
        "    \n",
        "    # Sort by batter and date for time-series operations\n",
        "    player_match = player_match.sort_values([\"batter\", \"date\"])\n",
        "    \n",
        "    print(f\"Player-match level data shape: {player_match.shape}\")\n",
        "    print(f\"Sample data:\")\n",
        "    print(player_match.head())\n",
        "    \n",
        "    return player_match\n",
        "\n",
        "# Aggregate data to player-match level\n",
        "player_match = aggregate_to_player_match(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Engineering PUT Features (Player vs Team)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "3.1 ENGINEERING PUT FEATURES\n",
            "============================================================\n",
            "PUT features created:\n",
            "           batter                 bowling_team  batsman_runs    put_avg  \\\n",
            "0  A Ashish Reddy               Mumbai Indians            10  13.500000   \n",
            "1  A Ashish Reddy          Chennai Super Kings             3  15.000000   \n",
            "2  A Ashish Reddy                 Punjab Kings             8  12.333333   \n",
            "3  A Ashish Reddy             Rajasthan Royals            10  12.333333   \n",
            "4  A Ashish Reddy  Royal Challengers Bangalore             4  13.250000   \n",
            "\n",
            "   put_avg_expanding  \n",
            "0           8.500000  \n",
            "1                NaN  \n",
            "2          13.000000  \n",
            "3          12.333333  \n",
            "4          12.333333  \n"
          ]
        }
      ],
      "source": [
        "def engineer_put_features(player_match):\n",
        "    \"\"\"Create Player vs Team (PUT) features\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"3.1 ENGINEERING PUT FEATURES\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # PUT (Player vs Team) average - overall average against bowling team\n",
        "    player_match[\"put_avg\"] = player_match.groupby([\"batter\", \"bowling_team\"])[\"batsman_runs\"].transform(\"mean\")\n",
        "    \n",
        "    # PUT average with expanding mean (cumulative performance)\n",
        "    put_expanding = player_match.groupby([\"batter\", \"bowling_team\"])[\"batsman_runs\"]\\\n",
        "        .expanding().mean().shift(1, fill_value=np.nan)\n",
        "    # Reset index to match original dataframe\n",
        "    put_expanding = put_expanding.reset_index(level=[0,1], drop=True)\n",
        "    player_match[\"put_avg_expanding\"] = put_expanding\n",
        "    \n",
        "    print(\"PUT features created:\")\n",
        "    print(player_match[[\"batter\", \"bowling_team\", \"batsman_runs\", \"put_avg\", \"put_avg_expanding\"]].head())\n",
        "    \n",
        "    return player_match\n",
        "\n",
        "# Create PUT features\n",
        "player_match = engineer_put_features(player_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Engineering Rolling Form Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "3.2 ENGINEERING ROLLING FORM FEATURES\n",
            "============================================================\n",
            "Rolling form features created:\n",
            "            batter       date  batsman_runs  rolling_avg_5  rolling_sr_5\n",
            "0   A Ashish Reddy 2012-04-29            10          10.00       100.000\n",
            "1   A Ashish Reddy 2012-05-04             3           6.50       100.000\n",
            "2   A Ashish Reddy 2012-05-08             8           7.00       100.000\n",
            "3   A Ashish Reddy 2012-05-18            10           7.75       137.500\n",
            "4   A Ashish Reddy 2012-05-20             4           7.00       126.000\n",
            "5   A Ashish Reddy 2013-04-05             7           6.40       141.000\n",
            "6   A Ashish Reddy 2013-04-07            14           8.60       144.334\n",
            "14  A Ashish Reddy 2013-04-09             3           7.60       139.334\n",
            "7   A Ashish Reddy 2013-04-12            16           8.80       124.890\n",
            "8   A Ashish Reddy 2013-04-14             4           8.80       124.890\n"
          ]
        }
      ],
      "source": [
        "def engineer_rolling_features(player_match):\n",
        "    \"\"\"Create rolling form features (last 5 matches)\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"3.2 ENGINEERING ROLLING FORM FEATURES\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Rolling average of last 5 matches\n",
        "    player_match[\"rolling_avg_5\"] = player_match.groupby(\"batter\")[\"batsman_runs\"]\\\n",
        "        .rolling(5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "    \n",
        "    # Rolling strike rate of last 5 matches\n",
        "    player_match[\"rolling_sr_5\"] = player_match.groupby(\"batter\")[\"strike_rate\"]\\\n",
        "        .rolling(5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "    \n",
        "    print(\"Rolling form features created:\")\n",
        "    print(player_match[[\"batter\", \"date\", \"batsman_runs\", \"rolling_avg_5\", \"rolling_sr_5\"]].head(10))\n",
        "    \n",
        "    return player_match\n",
        "\n",
        "# Create rolling form features\n",
        "player_match = engineer_rolling_features(player_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 Engineering Venue Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "3.3 ENGINEERING VENUE FEATURES\n",
            "============================================================\n",
            "Venue features created:\n",
            "           batter                                      venue  batsman_runs  \\\n",
            "0  A Ashish Reddy                           Wankhede Stadium            10   \n",
            "1  A Ashish Reddy            MA Chidambaram Stadium, Chepauk             3   \n",
            "2  A Ashish Reddy  Rajiv Gandhi International Stadium, Uppal             8   \n",
            "3  A Ashish Reddy  Rajiv Gandhi International Stadium, Uppal            10   \n",
            "4  A Ashish Reddy  Rajiv Gandhi International Stadium, Uppal             4   \n",
            "\n",
            "   venue_avg  venue_overall_avg  \n",
            "0       10.0          19.918951  \n",
            "1       19.5          20.362216  \n",
            "2        9.1          20.465774  \n",
            "3        9.1          20.465774  \n",
            "4        9.1          20.465774  \n"
          ]
        }
      ],
      "source": [
        "def engineer_venue_features(player_match):\n",
        "    \"\"\"Create venue average features\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"3.3 ENGINEERING VENUE FEATURES\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Venue average for each batter\n",
        "    player_match[\"venue_avg\"] = player_match.groupby([\"batter\", \"venue\"])[\"batsman_runs\"].transform(\"mean\")\n",
        "    \n",
        "    # Overall venue average\n",
        "    player_match[\"venue_overall_avg\"] = player_match.groupby(\"venue\")[\"batsman_runs\"].transform(\"mean\")\n",
        "    \n",
        "    print(\"Venue features created:\")\n",
        "    print(player_match[[\"batter\", \"venue\", \"batsman_runs\", \"venue_avg\", \"venue_overall_avg\"]].head())\n",
        "    \n",
        "    return player_match\n",
        "\n",
        "# Create venue features\n",
        "player_match = engineer_venue_features(player_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.4 Engineering PvP Features (Player vs Player)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "3.4 ENGINEERING PVP FEATURES\n",
            "============================================================\n",
            "PvP features created:\n",
            "           batter  match_id  batsman_runs  pvp_avg\n",
            "0  A Ashish Reddy       346            10      NaN\n",
            "1  A Ashish Reddy       352             3    10.00\n",
            "2  A Ashish Reddy       359             8     6.50\n",
            "3  A Ashish Reddy       373            10     7.00\n",
            "4  A Ashish Reddy       376             4     7.75\n"
          ]
        }
      ],
      "source": [
        "def engineer_pvp_features(player_match, df):\n",
        "    \"\"\"Create Player vs Player (PvP) features\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"3.4 ENGINEERING PVP FEATURES\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # For PvP, we need to consider the specific bowlers faced\n",
        "    # First, get ball-by-ball data with bowler information\n",
        "    pvp_data = df.groupby([\"batter\", \"bowler\", \"match_id\"])[\"batsman_runs\"].sum().reset_index()\n",
        "    pvp_data = pvp_data.sort_values([\"batter\", \"match_id\"])\n",
        "    \n",
        "    # Calculate PvP expanding average\n",
        "    pvp_expanding = pvp_data.groupby([\"batter\", \"bowler\"])[\"batsman_runs\"]\\\n",
        "        .expanding().mean().shift(1, fill_value=np.nan)\n",
        "    pvp_expanding = pvp_expanding.reset_index(level=[0,1], drop=True)\n",
        "    pvp_data[\"pvp_avg\"] = pvp_expanding\n",
        "    \n",
        "    # Merge back to player-match level (take average of all bowlers faced in the match)\n",
        "    pvp_match_avg = pvp_data.groupby([\"batter\", \"match_id\"])[\"pvp_avg\"].mean().reset_index()\n",
        "    player_match = player_match.merge(pvp_match_avg, on=[\"batter\", \"match_id\"], how=\"left\")\n",
        "    \n",
        "    print(\"PvP features created:\")\n",
        "    print(player_match[[\"batter\", \"match_id\", \"batsman_runs\", \"pvp_avg\"]].head())\n",
        "    \n",
        "    return player_match\n",
        "\n",
        "# Create PvP features\n",
        "player_match = engineer_pvp_features(player_match, df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5 Engineering Career Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "3.5 ENGINEERING CAREER FEATURES\n",
            "============================================================\n",
            "Career features created:\n",
            "           batter       date  batsman_runs  career_avg   career_sr  \\\n",
            "0  A Ashish Reddy 2012-04-29            10         NaN         NaN   \n",
            "1  A Ashish Reddy 2012-05-04             3   10.000000  100.000000   \n",
            "2  A Ashish Reddy 2012-05-08             8    6.500000  100.000000   \n",
            "3  A Ashish Reddy 2012-05-18            10    7.000000  100.000000   \n",
            "4  A Ashish Reddy 2012-05-20             4    7.750000  137.500000   \n",
            "5  A Ashish Reddy 2013-04-05             7    7.000000  126.000000   \n",
            "6  A Ashish Reddy 2013-04-07            14    7.000000  134.166667   \n",
            "7  A Ashish Reddy 2013-04-09             3    8.000000  131.667143   \n",
            "8  A Ashish Reddy 2013-04-12            16    7.375000  124.583750   \n",
            "9  A Ashish Reddy 2013-04-14             4    8.333333  130.494444   \n",
            "\n",
            "   career_matches  \n",
            "0               0  \n",
            "1               1  \n",
            "2               2  \n",
            "3               3  \n",
            "4               4  \n",
            "5               5  \n",
            "6               6  \n",
            "7               7  \n",
            "8               8  \n",
            "9               9  \n"
          ]
        }
      ],
      "source": [
        "def engineer_career_features(player_match):\n",
        "    \"\"\"Create career average features\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"3.5 ENGINEERING CAREER FEATURES\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Career average using expanding mean\n",
        "    career_avg_expanding = player_match.groupby(\"batter\")[\"batsman_runs\"]\\\n",
        "        .expanding().mean().shift(1, fill_value=np.nan)\n",
        "    career_avg_expanding = career_avg_expanding.reset_index(level=0, drop=True)\n",
        "    player_match[\"career_avg\"] = career_avg_expanding\n",
        "    \n",
        "    # Career strike rate using expanding mean\n",
        "    career_sr_expanding = player_match.groupby(\"batter\")[\"strike_rate\"]\\\n",
        "        .expanding().mean().shift(1, fill_value=np.nan)\n",
        "    career_sr_expanding = career_sr_expanding.reset_index(level=0, drop=True)\n",
        "    player_match[\"career_sr\"] = career_sr_expanding\n",
        "    \n",
        "    # Career matches played\n",
        "    player_match[\"career_matches\"] = player_match.groupby(\"batter\").cumcount()\n",
        "    \n",
        "    print(\"Career features created:\")\n",
        "    print(player_match[[\"batter\", \"date\", \"batsman_runs\", \"career_avg\", \"career_sr\", \"career_matches\"]].head(10))\n",
        "    \n",
        "    return player_match\n",
        "\n",
        "# Create career features\n",
        "player_match = engineer_career_features(player_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Creating Target Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "4. CREATING TARGET LABELS\n",
            "============================================================\n",
            "Data after creating targets: (8648, 24)\n",
            "Target statistics:\n",
            "Next match runs - Mean: 20.18, Std: 21.04\n",
            "Next match SR - Mean: 107.75, Std: 61.80\n"
          ]
        }
      ],
      "source": [
        "def create_target_labels(player_match):\n",
        "    \"\"\"Create target labels (next match performance)\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"4. CREATING TARGET LABELS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Create target: runs in next match\n",
        "    player_match = player_match.sort_values([\"batter\", \"date\"])\n",
        "    player_match[\"target_next_runs\"] = player_match.groupby(\"batter\")[\"batsman_runs\"].shift(-1)\n",
        "    \n",
        "    # Create target: strike rate in next match\n",
        "    player_match[\"target_next_sr\"] = player_match.groupby(\"batter\")[\"strike_rate\"].shift(-1)\n",
        "    \n",
        "    # Remove rows where target is NaN (last match for each player)\n",
        "    player_match_clean = player_match.dropna(subset=[\"target_next_runs\"])\n",
        "    \n",
        "    print(f\"Data after creating targets: {player_match_clean.shape}\")\n",
        "    print(f\"Target statistics:\")\n",
        "    print(f\"Next match runs - Mean: {player_match_clean[\"target_next_runs\"].mean():.2f}, Std: {player_match_clean[\"target_next_runs\"].std():.2f}\")\n",
        "    print(f\"Next match SR - Mean: {player_match_clean[\"target_next_sr\"].mean():.2f}, Std: {player_match_clean[\"target_next_sr\"].std():.2f}\")\n",
        "    \n",
        "    return player_match_clean\n",
        "\n",
        "# Create target labels\n",
        "player_match_clean = create_target_labels(player_match)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature Selection and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "5. FEATURE SELECTION AND PREPROCESSING\n",
            "============================================================\n",
            "Features shape: (8648, 14)\n",
            "Features selected: ['put_avg', 'put_avg_expanding', 'rolling_avg_5', 'rolling_sr_5', 'venue_avg', 'venue_overall_avg', 'pvp_avg', 'career_avg', 'career_sr', 'career_matches', 'ball', 'is_boundary', 'is_six', 'is_four']\n",
            "Feature statistics:\n",
            "           put_avg  put_avg_expanding  rolling_avg_5  rolling_sr_5  \\\n",
            "count  8648.000000        8648.000000    8648.000000   8648.000000   \n",
            "mean     20.186318          20.327960      20.334908    107.868005   \n",
            "std      11.678431          14.778165      12.388231     33.612365   \n",
            "min       0.000000           0.000000       0.000000      0.000000   \n",
            "25%      11.285714           9.000000      11.000000     87.913000   \n",
            "50%      20.266667          19.000000      19.000000    107.495000   \n",
            "75%      27.428571          28.333333      27.800000    127.924500   \n",
            "max     120.000000         158.000000     158.000000    366.670000   \n",
            "\n",
            "         venue_avg  venue_overall_avg      pvp_avg   career_avg    career_sr  \\\n",
            "count  8648.000000        8648.000000  8648.000000  8648.000000  8648.000000   \n",
            "mean     20.201583          19.825115    20.678574    20.295648   108.141265   \n",
            "std      13.290685           1.575890     9.859020     9.836501    26.228323   \n",
            "min       0.000000          14.787879     0.000000     0.000000     0.000000   \n",
            "25%      10.000000          19.372093    14.500000    14.142857    97.079409   \n",
            "50%      19.333333          19.932783    21.702479    21.142857   110.008051   \n",
            "75%      28.304348          20.465774    26.706495    26.758966   122.132922   \n",
            "max     114.000000          25.684211   116.000000   158.000000   366.670000   \n",
            "\n",
            "       career_matches         ball  is_boundary       is_six      is_four  \n",
            "count     8648.000000  8648.000000  8648.000000  8648.000000  8648.000000  \n",
            "mean        32.669172    16.422179     1.281105     0.554810     0.726295  \n",
            "std         31.953090    14.087953     2.316908     1.085775     1.291329  \n",
            "min          0.000000     1.000000     0.000000     0.000000     0.000000  \n",
            "25%          7.000000     5.000000     0.000000     0.000000     0.000000  \n",
            "50%         22.000000    12.000000     0.000000     0.000000     0.000000  \n",
            "75%         49.000000    24.000000     2.000000     1.000000     1.000000  \n",
            "max        154.000000    77.000000    30.000000    13.000000    17.000000  \n"
          ]
        }
      ],
      "source": [
        "def feature_selection_and_preprocessing(player_match_clean):\n",
        "    \"\"\"Select features and handle preprocessing\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"5. FEATURE SELECTION AND PREPROCESSING\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Select features for modeling\n",
        "    feature_columns = [\n",
        "        \"put_avg\", \"put_avg_expanding\",\n",
        "        \"rolling_avg_5\", \"rolling_sr_5\",\n",
        "        \"venue_avg\", \"venue_overall_avg\",\n",
        "        \"pvp_avg\",\n",
        "        \"career_avg\", \"career_sr\", \"career_matches\",\n",
        "        \"ball\", \"is_boundary\", \"is_six\", \"is_four\"\n",
        "    ]\n",
        "    \n",
        "    # Handle missing values in features\n",
        "    for col in feature_columns:\n",
        "        if col in player_match_clean.columns:\n",
        "            player_match_clean[col] = player_match_clean[col].fillna(player_match_clean[col].median())\n",
        "    \n",
        "    features = player_match_clean[feature_columns]\n",
        "    labels_runs = player_match_clean[\"target_next_runs\"]\n",
        "    labels_sr = player_match_clean[\"target_next_sr\"]\n",
        "    \n",
        "    print(f\"Features shape: {features.shape}\")\n",
        "    print(f\"Features selected: {feature_columns}\")\n",
        "    print(f\"Feature statistics:\")\n",
        "    print(features.describe())\n",
        "    \n",
        "    return features, labels_runs, labels_sr, feature_columns\n",
        "\n",
        "# Select features and preprocess\n",
        "features, labels_runs, labels_sr, feature_columns = feature_selection_and_preprocessing(player_match_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Time-Series Aware Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "6. TIME-SERIES AWARE TRAIN-TEST SPLIT\n",
            "============================================================\n",
            "Train set size: 6918 (80.0%)\n",
            "Test set size: 1730 (20.0%)\n",
            "Train date range: 2008-04-18 00:00:00 to 2015-05-04 00:00:00\n",
            "Test date range: 2015-05-04 00:00:00 to 2017-05-16 00:00:00\n"
          ]
        }
      ],
      "source": [
        "def time_series_split(features, labels_runs, labels_sr, player_match_clean):\n",
        "    \"\"\"Perform time-series aware train-test split\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"6. TIME-SERIES AWARE TRAIN-TEST SPLIT\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Sort by date for proper time-series split\n",
        "    player_match_clean = player_match_clean.sort_values(\"date\")\n",
        "    \n",
        "    # Time-series split (80% train, 20% test)\n",
        "    split_idx = int(len(player_match_clean) * 0.8)\n",
        "    \n",
        "    X_train = features[:split_idx]\n",
        "    X_test = features[split_idx:]\n",
        "    y_train_runs = labels_runs[:split_idx]\n",
        "    y_test_runs = labels_runs[split_idx:]\n",
        "    y_train_sr = labels_sr[:split_idx]\n",
        "    y_test_sr = labels_sr[split_idx:]\n",
        "    \n",
        "    print(f\"Train set size: {len(X_train)} ({len(X_train)/len(features)*100:.1f}%)\")\n",
        "    print(f\"Test set size: {len(X_test)} ({len(X_test)/len(features)*100:.1f}%)\")\n",
        "    print(f\"Train date range: {player_match_clean.iloc[:split_idx][\"date\"].min()} to {player_match_clean.iloc[:split_idx][\"date\"].max()}\")\n",
        "    print(f\"Test date range: {player_match_clean.iloc[split_idx:][\"date\"].min()} to {player_match_clean.iloc[split_idx:][\"date\"].max()}\")\n",
        "    \n",
        "    return X_train, X_test, y_train_runs, y_test_runs, y_train_sr, y_test_sr\n",
        "\n",
        "# Perform time-series split\n",
        "X_train, X_test, y_train_runs, y_test_runs, y_train_sr, y_test_sr = time_series_split(\n",
        "    features, labels_runs, labels_sr, player_match_clean\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Creating Feature Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "7. CREATING FEATURE PIPELINE\n",
            "============================================================\n",
            "Feature pipeline created and applied:\n",
            "Scaled training data shape: (6918, 14)\n",
            "Scaled test data shape: (1730, 14)\n",
            "Sample scaled features:\n",
            "    put_avg  put_avg_expanding  rolling_avg_5  rolling_sr_5  venue_avg  \\\n",
            "0 -0.537849          -0.769929      -0.809109     -0.221044  -0.737760   \n",
            "1 -0.410843          -0.063189      -1.091993     -0.221044  -0.027581   \n",
            "2 -0.636631          -0.467041      -1.051581     -0.221044  -0.805040   \n",
            "3 -0.636631          -0.511913      -0.990963      0.890980  -0.805040   \n",
            "4 -0.559016          -0.511913      -1.051581      0.549959  -0.805040   \n",
            "\n",
            "   venue_overall_avg   pvp_avg  career_avg  career_sr  career_matches  \\\n",
            "0           0.057440  0.128962    0.111646   0.115105       -1.017722   \n",
            "1           0.338648 -1.040630   -0.997523  -0.270829       -0.985256   \n",
            "2           0.404345 -1.390433   -1.345916  -0.270829       -0.952790   \n",
            "3           0.404345 -1.340462   -1.296146  -0.270829       -0.920324   \n",
            "4           0.404345 -1.265504   -1.221490   1.175259       -0.887857   \n",
            "\n",
            "       ball  is_boundary    is_six   is_four  \n",
            "0 -0.442923    -0.106196 -0.502749  0.228572  \n",
            "1 -0.938992    -0.543497 -0.502749 -0.551913  \n",
            "2 -0.584657    -0.543497 -0.502749 -0.551913  \n",
            "3 -0.868125    -0.543497 -0.502749 -0.551913  \n",
            "4 -0.797258    -0.543497 -0.502749 -0.551913  \n"
          ]
        }
      ],
      "source": [
        "def create_feature_pipeline(X_train, X_test, feature_columns):\n",
        "    \"\"\"Create and apply feature preprocessing pipeline\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"7. CREATING FEATURE PIPELINE\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Create preprocessing pipeline\n",
        "    feature_pipeline = Pipeline([\n",
        "        (\"scaler\", StandardScaler())\n",
        "    ])\n",
        "    \n",
        "    # Fit pipeline on training data\n",
        "    X_train_scaled = feature_pipeline.fit_transform(X_train)\n",
        "    X_test_scaled = feature_pipeline.transform(X_test)\n",
        "    \n",
        "    # Convert back to DataFrame for easier handling\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns)\n",
        "    \n",
        "    print(\"Feature pipeline created and applied:\")\n",
        "    print(f\"Scaled training data shape: {X_train_scaled.shape}\")\n",
        "    print(f\"Scaled test data shape: {X_test_scaled.shape}\")\n",
        "    print(f\"Sample scaled features:\")\n",
        "    print(X_train_scaled.head())\n",
        "    \n",
        "    return feature_pipeline, X_train_scaled, X_test_scaled\n",
        "\n",
        "# Create feature pipeline\n",
        "feature_pipeline, X_train_scaled, X_test_scaled = create_feature_pipeline(X_train, X_test, feature_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Saving Artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "8. SAVING ARTIFACTS\n",
            "============================================================\n",
            "Artifacts saved successfully:\n",
            "- feature_pipeline.pkl: Preprocessing pipeline\n",
            "- dataset.csv: Complete feature-engineered dataset\n",
            "- train_data.csv: Training set\n",
            "- test_data.csv: Test set\n"
          ]
        }
      ],
      "source": [
        "def save_artifacts(feature_pipeline, final_dataset, X_train, X_test, y_train_runs, y_test_runs, y_train_sr, y_test_sr, feature_columns):\n",
        "    \"\"\"Save all artifacts\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"8. SAVING ARTIFACTS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Save the feature pipeline\n",
        "    joblib.dump(feature_pipeline, \"feature_pipeline.pkl\")\n",
        "    \n",
        "    # Save the final dataset with all features and targets\n",
        "    final_dataset.to_csv(\"dataset.csv\", index=False)\n",
        "    \n",
        "    # Save train-test splits\n",
        "    train_data = pd.concat([X_train, y_train_runs, y_train_sr], axis=1)\n",
        "    train_data.columns = feature_columns + [\"target_runs\", \"target_sr\"]\n",
        "    train_data.to_csv(\"train_data.csv\", index=False)\n",
        "    \n",
        "    test_data = pd.concat([X_test, y_test_runs, y_test_sr], axis=1)\n",
        "    test_data.columns = feature_columns + [\"target_runs\", \"target_sr\"]\n",
        "    test_data.to_csv(\"test_data.csv\", index=False)\n",
        "    \n",
        "    print(\"Artifacts saved successfully:\")\n",
        "    print(\"- feature_pipeline.pkl: Preprocessing pipeline\")\n",
        "    print(\"- dataset.csv: Complete feature-engineered dataset\")\n",
        "    print(\"- train_data.csv: Training set\")\n",
        "    print(\"- test_data.csv: Test set\")\n",
        "\n",
        "# Save all artifacts\n",
        "save_artifacts(\n",
        "    feature_pipeline, player_match_clean, X_train, X_test, \n",
        "    y_train_runs, y_test_runs, y_train_sr, y_test_sr, feature_columns\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
